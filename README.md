# ğŸ¤– Auto-RAG Optimizer

> **Multi-Agent System for Automated RAG Pipeline Optimization**  
> No manual tuning. Just AI agents collaborating to improve your Retrieval-Augmented Generation.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-green.svg)](https://openai.com)
[![FAISS](https://img.shields.io/badge/vector-FAISS-orange.svg)](https://github.com/facebookresearch/faiss)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ¯ Problem â†’ Solution

**Problem**: RAG pipelines need manual tuning (chunk size, overlap, top-k, hybrid weights...)  
**Solution**: Let AI agents analyze, experiment, and optimize automatically.

```
Traditional Approach:        Auto-RAG Optimizer:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Manual tuning               4 AI Agents collaborate
Trial & error               Data-driven decisions
Hours of work               5-10 minutes automated
Guesswork                   LLM reasoning + metrics
```

---

## ğŸ—ï¸ Architecture: 4 Specialized AI Agents

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RAG OPTIMIZATION PIPELINE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Documents                    Test Queries
        â”‚                             â”‚
        â–¼                             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  STEP 1: Build Baseline Index            â”‚
   â”‚  â€¢ Chunk documents (default params)      â”‚
   â”‚  â€¢ Create embeddings + FAISS index       â”‚
   â”‚  â€¢ Build BM25 lexical index              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  ğŸ¤– AGENT #1: Retriever Profiler         â”‚
   â”‚  â€¢ Run test queries                      â”‚
   â”‚  â€¢ Measure: recall, diversity, scores    â”‚
   â”‚  â€¢ Detect issues (low scores, gaps)      â”‚
   â”‚  Output: retrieval_report.json           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  ğŸ§  AGENT #2: Chunk Architect            â”‚
   â”‚  â€¢ Analyze profiling report              â”‚
   â”‚  â€¢ Use GPT-4o-mini to reason             â”‚
   â”‚  â€¢ Propose optimal chunk_size + overlap  â”‚
   â”‚  Output: chunk_proposal.json             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  STEP 4: Rebuild Index (Optimized)       â”‚
   â”‚  â€¢ Re-chunk with new parameters          â”‚
   â”‚  â€¢ Rebuild FAISS + BM25 indexes          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  âš–ï¸ AGENT #3: Evaluator (Optional)       â”‚
   â”‚  â€¢ Compare baseline vs optimized         â”‚
   â”‚  â€¢ LLM-as-Judge: score answers           â”‚
   â”‚  â€¢ Win/Loss statistics                   â”‚
   â”‚  Output: evaluation_report.json          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  ğŸ¯ AGENT #4: Final Architect            â”‚
   â”‚  â€¢ Synthesize all reports                â”‚
   â”‚  â€¢ Generate production config            â”‚
   â”‚  Output: optimized_config.yaml           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Real Results (French Legal Documents)

**Test Case**: 9 queries on French Constitution & Labor Code

| Metric | Baseline | Optimized | Improvement |
|--------|----------|-----------|-------------|
| **Chunk Size** | 4000 words | 600 words | **-85%** (more granular) |
| **Chunk Overlap** | 0 words | 150 words | **Context preserved** |
| **Total Chunks** | 24 | 220 | **+196** (+817%) |
| **Answer Quality** | 8.89/10 | 9.00/10 | **+1.2%** |
| **Avg Retrieval Score** | 0.448 | 0.496 | **+10.9%** |
| **Top-1 Retrieval** | 0.494 | 0.540 | **+9.2%** |
| **Precision@3** | 63.0% | 85.2% | **+22.2pp** |
| **Excellent Answers (8-10)** | 100% | 100% | Maintained |

### ğŸ’¡ Key Insights

1. **Smaller chunks = Better precision**: Going from 4000 â†’ 600 words improved retrieval by **10.9%**
2. **Overlap matters**: Adding 150 words overlap preserved context across chunks
3. **Granularity helps**: 24 â†’ 220 chunks means better coverage and diversity
4. **Precision improved dramatically**: Precision@3 went from 63% â†’ 85% (**+22.2pp**)

---

## ğŸ—£ï¸ Real Example: Before vs After Optimization

### Example Question (French)
**"Quels sont les principes fondamentaux de la RÃ©publique franÃ§aise ?"**  
*(What are the fundamental principles of the French Republic?)*

---

### âŒ **BASELINE** (4000 words, 0 overlap)

**Score**: 9/10  
**Retrieval Scores**: [0.583, 0.510, 0.438]  
**Retrieved**: 3 chunks (very large chunks)

**Answer**:
> Les principes fondamentaux de la RÃ©publique franÃ§aise sont Ã©noncÃ©s dans le prÃ©ambule et les articles de la Constitution. Ils incluent :
> 
> 1. **IndivisibilitÃ©** : La France est une RÃ©publique indivisible, laÃ¯que, dÃ©mocratique et sociale (Article 1).
> 2. **Ã‰galitÃ©** : Elle assure l'Ã©galitÃ© devant la loi de tous les citoyens sans distinction d'origine, de race ou de religion (Article 1).
> 3. **Respect des croyances** : La RÃ©publique respecte toutes les croyances (Article 1).
> 4. **SouverainetÃ© nationale** : La souverainetÃ© nationale appartient au peuple qui l'exerce par ses reprÃ©sentants et par la voie du rÃ©fÃ©rendum (Article 3).
> 5. **LibertÃ©, Ã‰galitÃ©, FraternitÃ©** : La devise de la RÃ©publique est Â« LibertÃ©, Ã‰galitÃ©, FraternitÃ© Â» (Article 2).

**Issues**:
- âš ï¸ Large chunks (4000 words) capture too much irrelevant content
- âš ï¸ Low retrieval precision (0.438 for 3rd chunk)
- âš ï¸ No overlap = context fragmentation

---

### âœ… **OPTIMIZED** (600 words, 150 overlap)

**Score**: 9/10  
**Retrieval Scores**: [0.661, 0.519, 0.513]  
**Retrieved**: 5 chunks (focused, precise chunks)

**Answer**:
> Les principes fondamentaux de la RÃ©publique franÃ§aise, tels qu'Ã©noncÃ©s dans la Constitution, incluent :
>
> 1. **IndivisibilitÃ©** : La France est une RÃ©publique indivisible, laÃ¯que, dÃ©mocratique et sociale (Article 1).
> 2. **Ã‰galitÃ©** : Elle assure l'Ã©galitÃ© devant la loi de tous les citoyens sans distinction d'origine, de race ou de religion (Article 1).
> 3. **SouverainetÃ© nationale** : La souverainetÃ© nationale appartient au peuple, qui l'exerce par ses reprÃ©sentants et par la voie du rÃ©fÃ©rendum (Article 3).
> 4. **LibertÃ©** : La devise de la RÃ©publique est Â« LibertÃ©, Ã‰galitÃ©, FraternitÃ© Â» (Article 2).
> 5. **Respect des croyances** : La RÃ©publique respecte toutes les croyances.
> 6. **DÃ©mocratie** : Le principe est un gouvernement du peuple, par le peuple et pour le peuple (Article 2).
>
> Ces principes sont Ã©galement renforcÃ©s par l'attachement aux Droits de l'homme et aux droits et devoirs dÃ©finis dans la Charte de l'environnement de 2004 (PrÃ©ambule de la Constitution).

**Improvements**:
- âœ… **Higher retrieval scores** (0.661 vs 0.583 for top-1)
- âœ… **Better precision** across all retrieved chunks
- âœ… **More comprehensive answer** with additional context (point 6 + PrÃ©ambule)
- âœ… **Better source citations** thanks to overlap preserving context

---

## ğŸ“ˆ Why Did It Improve?

### Problem with Large Chunks (4000 words)
```
[â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€]
â”‚  Introduction â”‚ Relevant Info â”‚ Irrelevant Content â”‚ More Text â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†‘
                Only this part is relevant
                but entire chunk is scored
```

### Solution with Optimized Chunks (600 words + overlap)
```
[â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€]  [â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€]  [â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€]
â”‚  Relevant 1 â”‚  â”‚  Relevant 2 â”‚  â”‚  Relevant 3 â”‚
â””â”€â”€overlapâ”€â”€â”˜    â””â”€â”€overlapâ”€â”€â”˜    â””â”€â”€overlapâ”€â”€â”˜
      â†‘              â†‘               â†‘
   Each chunk focused on one topic
   Overlap preserves context
   Better retrieval precision
```

**Key Improvements**:
1. **Smaller chunks** = each chunk focuses on ONE topic â†’ higher semantic similarity
2. **Overlap** = context flows between chunks â†’ no information loss
3. **More chunks** = better coverage of document â†’ higher recall
4. **Higher precision** = less irrelevant content â†’ better answer quality

---

## ğŸ› ï¸ Tech Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Component       â”‚ Technology                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Agent LLM       â”‚ OpenAI GPT-4o-mini (reasoning)          â”‚
â”‚ Embeddings      â”‚ OpenAI text-embedding-3-small           â”‚
â”‚ Vector Search   â”‚ FAISS (IndexFlatL2)                     â”‚
â”‚ Lexical Search  â”‚ BM25 (rank-bm25)                        â”‚
â”‚ Orchestration   â”‚ Python 3.11+ (custom multi-agent)       â”‚
â”‚ Evaluation      â”‚ LLM-as-Judge (GPT-4o-mini)              â”‚
â”‚ Storage         â”‚ JSON reports + YAML configs             â”‚
â”‚ Cost            â”‚ ~$0.02-0.05 per optimization run        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start (3 Steps)

### 1ï¸âƒ£ Clone & Install
```bash
git clone https://github.com/Bellilty/auto-rag-optimizer.git
cd auto-rag-optimizer
python3.11 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2ï¸âƒ£ Set OpenAI API Key
```bash
export OPENAI_API_KEY="sk-your-key-here"
# Or create .env file with OPENAI_API_KEY=sk-...
```

### 3ï¸âƒ£ Run Optimization
```bash
# Add your documents to data/raw_docs/
# Add test queries to src/configs/test_queries.json

python examples/sample_run.py
```

**That's it!** The agents will:
- Profile your baseline RAG
- Propose optimized chunking
- Rebuild indexes
- Evaluate improvements
- Generate production config

**Output**: `outputs/optimized_config.yaml` + detailed reports

---

## ğŸ“‚ Project Structure

```
auto-rag-optimizer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                 # 4 specialized AI agents
â”‚   â”‚   â”œâ”€â”€ retriever_profiler_agent.py
â”‚   â”‚   â”œâ”€â”€ chunk_architect_agent.py
â”‚   â”‚   â”œâ”€â”€ evaluator_agent.py
â”‚   â”‚   â””â”€â”€ architect_agent.py
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â””â”€â”€ workflow.py         # Multi-agent pipeline
â”‚   â”œâ”€â”€ components/             # RAG building blocks
â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â”œâ”€â”€ index_builder.py
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â””â”€â”€ evaluator.py
â”‚   â”œâ”€â”€ tools/                  # Utilities
â”‚   â”‚   â”œâ”€â”€ llm_tools.py
â”‚   â”‚   â”œâ”€â”€ retriever_tools.py
â”‚   â”‚   â””â”€â”€ evaluation_tools.py
â”‚   â””â”€â”€ configs/
â”‚       â”œâ”€â”€ base_config.yaml    # Starting point
â”‚       â””â”€â”€ test_queries.json   # Evaluation data
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_docs/               # Your documents (PDF, TXT)
â”‚   â””â”€â”€ index/                  # Generated indexes
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ optimized_config.yaml   # ğŸ¯ Final result
â”‚   â””â”€â”€ reports/                # Agent reports (JSON)
â””â”€â”€ examples/
    â””â”€â”€ sample_run.py           # Full demo script
```

---

## ğŸ’¡ Key Features

âœ… **Fully Automated** â€“ No manual parameter tuning  
âœ… **Multi-Agent** â€“ 4 specialized LLM agents collaborate  
âœ… **Data-Driven** â€“ Decisions based on metrics + LLM reasoning  
âœ… **Hybrid Search** â€“ Combines vector (FAISS) + lexical (BM25)  
âœ… **LLM-as-Judge** â€“ Evaluates answer quality objectively  
âœ… **Production-Ready** â€“ Outputs clean YAML configuration  
âœ… **Cost-Efficient** â€“ ~$0.02-0.05 per optimization run  
âœ… **Extensible** â€“ Easy to add custom agents or metrics  

---

## ğŸ§ª Example Use Cases

| Domain | Documents | Optimization Focus |
|--------|-----------|-------------------|
| **Legal** | Laws, court decisions | Precise chunking for citations |
| **Medical** | Research papers, protocols | Context preservation across chunks |
| **Customer Support** | FAQs, tickets | Fast retrieval, diverse sources |
| **Technical Docs** | API docs, guides | Code snippet integrity |
| **Finance** | Reports, regulations | Numerical data accuracy |

---

## ğŸ”¬ Evaluation Metrics Explained

### 1. **Answer Quality (LLM-as-Judge)**
GPT-4o-mini scores each answer (1-10) based on:
- Relevance
- Completeness  
- Accuracy
- Conciseness

### 2. **Retrieval Score (Cosine Similarity)**
- Semantic similarity between query and retrieved chunks
- Range: 0.0 (completely different) â†’ 1.0 (identical)
- **Higher is better**

### 3. **Top-1 Retrieval Score**
- Similarity score of the BEST retrieved chunk
- Critical for answer quality
- **Target: > 0.5**

### 4. **Precision@K**
- Percentage of top-K chunks that are relevant (score > 0.4)
- Measures retrieval accuracy
- **Target: > 70%**

---

## ğŸ“ˆ Agent Reasoning Example

**Chunk Architect Agent Analysis** (from actual run):

```yaml
Input (Profiling Report):
  - Current chunk_size: 4000 words
  - Current overlap: 0 words
  - Avg retrieval score: 0.413
  - Issues: Low source diversity, many low scores

Agent Reasoning (GPT-4o-mini):
  "The current average retrieval score of 0.413 indicates room 
   for improvement. The large chunk size (4000 words) captures 
   too much irrelevant content, diluting semantic similarity.
   
   Reducing chunk size to 600 words will:
   â€¢ Increase precision by focusing each chunk on one topic
   â€¢ Improve retrieval scores by reducing noise
   â€¢ Enable better source diversity
   
   Adding 150 words overlap (30%) will:
   â€¢ Preserve context across chunk boundaries
   â€¢ Prevent information fragmentation
   â€¢ Maintain answer completeness"

Proposed Output:
  - chunk_size: 600 words (-85%)
  - overlap: 150 words (+150 words)
  - confidence: HIGH
  
Expected Impact:
  âœ“ +10-15% retrieval score improvement
  âœ“ +20-30pp precision improvement
  âœ“ Better answer consistency
```

**Result**: Retrieval improved by **+10.9%**, Precision@3 by **+22.2pp** âœ…

---

## ğŸŒŸ Why This Matters

**Traditional RAG Development**:
- â° Hours of manual experimentation
- ğŸ² Trial and error, guesswork
- ğŸ“‰ Suboptimal configurations
- ğŸ’¸ Wasted API costs on poor retrievals

**With Auto-RAG Optimizer**:
- âš¡ 5-10 minutes automated
- ğŸ¤– AI reasoning + data analysis
- ğŸ“ˆ Measurable, reproducible results
- ğŸ’° Optimized for quality AND cost

---

## ğŸ¤ Contributing

Contributions welcome! Ideas:
- Add more agents (e.g., RerankerAgent, PromptAgent)
- Support more vector DBs (Pinecone, Weaviate, Qdrant)
- Custom evaluation metrics
- Multi-language support
- Web UI (Gradio/Streamlit)

---

## ğŸ“ License

MIT License - Free for personal and commercial use.

---

## ğŸ”— Links

- **GitHub**: [Bellilty/auto-rag-optimizer](https://github.com/Bellilty/auto-rag-optimizer)
- **Issues**: [Report bugs or request features](https://github.com/Bellilty/auto-rag-optimizer/issues)

---

<div align="center">

**Built with â¤ï¸ for the RAG community**

*If you find this useful, star the repo â­ and share on LinkedIn!*

[![Star on GitHub](https://img.shields.io/github/stars/Bellilty/auto-rag-optimizer?style=social)](https://github.com/Bellilty/auto-rag-optimizer)

</div>
