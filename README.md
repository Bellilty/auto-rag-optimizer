# ğŸ¤– Auto-RAG Optimizer

> **Multi-Agent System for Automated RAG Pipeline Optimization**  
> No manual tuning. Just AI agents collaborating to improve your Retrieval-Augmented Generation.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-green.svg)](https://openai.com)
[![FAISS](https://img.shields.io/badge/vector-FAISS-orange.svg)](https://github.com/facebookresearch/faiss)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ¯ Problem â†’ Solution

**Problem**: RAG pipelines need manual tuning (chunk size, overlap, top-k, hybrid weights...)  
**Solution**: Let AI agents analyze, experiment, and optimize automatically.

```
Traditional Approach:        Auto-RAG Optimizer:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Manual tuning               4 AI Agents collaborate
Trial & error               Data-driven decisions
Hours of work               5-10 minutes automated
Guesswork                   LLM reasoning + metrics
```

---

## ğŸ—ï¸ Architecture: 4 Specialized AI Agents

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RAG OPTIMIZATION PIPELINE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Documents                    Test Queries
        â”‚                             â”‚
        â–¼                             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  STEP 1: Build Baseline Index            â”‚
   â”‚  â€¢ Chunk documents (default params)      â”‚
   â”‚  â€¢ Create embeddings + FAISS index       â”‚
   â”‚  â€¢ Build BM25 lexical index              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  ğŸ¤– AGENT #1: Retriever Profiler         â”‚
   â”‚  â€¢ Run test queries                      â”‚
   â”‚  â€¢ Measure: recall, diversity, scores    â”‚
   â”‚  â€¢ Detect issues (low scores, gaps)      â”‚
   â”‚  Output: retrieval_report.json           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  ğŸ§  AGENT #2: Chunk Architect            â”‚
   â”‚  â€¢ Analyze profiling report              â”‚
   â”‚  â€¢ Use GPT-4o-mini to reason             â”‚
   â”‚  â€¢ Propose optimal chunk_size + overlap  â”‚
   â”‚  Output: chunk_proposal.json             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  STEP 4: Rebuild Index (Optimized)       â”‚
   â”‚  â€¢ Re-chunk with new parameters          â”‚
   â”‚  â€¢ Rebuild FAISS + BM25 indexes          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  âš–ï¸ AGENT #3: Evaluator (Optional)       â”‚
   â”‚  â€¢ Compare baseline vs optimized         â”‚
   â”‚  â€¢ LLM-as-Judge: score answers           â”‚
   â”‚  â€¢ Win/Loss statistics                   â”‚
   â”‚  Output: evaluation_report.json          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  ğŸ¯ AGENT #4: Final Architect            â”‚
   â”‚  â€¢ Synthesize all reports                â”‚
   â”‚  â€¢ Generate production config            â”‚
   â”‚  Output: optimized_config.yaml           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Real Results (French Legal Documents)

| Metric                  | Baseline   | Optimized | Improvement           |
| ----------------------- | ---------- | --------- | --------------------- |
| **Chunk Size**          | 1000 words | 600 words | Smaller, more precise |
| **Overlap**             | 200 words  | 150 words | Optimized context     |
| **Avg Retrieval Score** | 0.52       | 0.68      | **+31%**              |
| **Source Diversity**    | Low        | High      | Better coverage       |
| **Answer Quality**      | 6.2/10     | 8.1/10    | **+30%**              |
| **Cost per Query**      | $0.003     | $0.002    | Lower (fewer tokens)  |

**Key Insight**: Smaller chunks = higher precision = better answers for legal Q&A

---

## ğŸ› ï¸ Tech Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Component       â”‚ Technology                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Agent LLM       â”‚ OpenAI GPT-4o-mini (reasoning)          â”‚
â”‚ Embeddings      â”‚ OpenAI text-embedding-3-small           â”‚
â”‚ Vector Search   â”‚ FAISS (IndexFlatL2)                     â”‚
â”‚ Lexical Search  â”‚ BM25 (rank-bm25)                        â”‚
â”‚ Orchestration   â”‚ Python 3.11+ (custom multi-agent)       â”‚
â”‚ Evaluation      â”‚ LLM-as-Judge (GPT-4o-mini)              â”‚
â”‚ Storage         â”‚ JSON reports + YAML configs             â”‚
â”‚ Cost            â”‚ ~$0.02-0.05 per optimization run        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start (3 Steps)

### 1ï¸âƒ£ Clone & Install

```bash
git clone https://github.com/Bellilty/auto-rag-optimizer.git
cd auto-rag-optimizer
python3.11 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2ï¸âƒ£ Set OpenAI API Key

```bash
export OPENAI_API_KEY="sk-your-key-here"
# Or create .env file with OPENAI_API_KEY=sk-...
```

### 3ï¸âƒ£ Run Optimization

```bash
# Add your documents to data/raw_docs/
# Add test queries to src/configs/test_queries.json

python examples/sample_run.py
```

**That's it!** The agents will:

- Profile your baseline RAG
- Propose optimized chunking
- Rebuild indexes
- Evaluate improvements
- Generate production config

**Output**: `outputs/optimized_config.yaml` + detailed reports

---

## ğŸ“‚ Project Structure

```
auto-rag-optimizer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                 # 4 specialized AI agents
â”‚   â”‚   â”œâ”€â”€ retriever_profiler_agent.py    # Profile baseline
â”‚   â”‚   â”œâ”€â”€ chunk_architect_agent.py        # Optimize chunking
â”‚   â”‚   â”œâ”€â”€ evaluator_agent.py              # Compare configs
â”‚   â”‚   â””â”€â”€ architect_agent.py              # Final config
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â””â”€â”€ workflow.py         # Multi-agent pipeline
â”‚   â”œâ”€â”€ components/             # RAG building blocks
â”‚   â”‚   â”œâ”€â”€ chunker.py          # Document chunking
â”‚   â”‚   â”œâ”€â”€ index_builder.py    # FAISS + BM25
â”‚   â”‚   â”œâ”€â”€ retriever.py        # Hybrid search
â”‚   â”‚   â””â”€â”€ evaluator.py        # LLM-as-Judge
â”‚   â”œâ”€â”€ tools/                  # Utilities
â”‚   â”‚   â”œâ”€â”€ llm_tools.py        # OpenAI wrapper
â”‚   â”‚   â”œâ”€â”€ retriever_tools.py  # Metrics
â”‚   â”‚   â””â”€â”€ evaluation_tools.py # Scoring
â”‚   â””â”€â”€ configs/
â”‚       â”œâ”€â”€ base_config.yaml    # Starting point
â”‚       â””â”€â”€ test_queries.json   # Evaluation data
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_docs/               # Your documents (PDF, TXT)
â”‚   â””â”€â”€ index/                  # Generated indexes
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ optimized_config.yaml   # ğŸ¯ Final result
â”‚   â””â”€â”€ reports/                # Agent reports (JSON)
â””â”€â”€ examples/
    â””â”€â”€ sample_run.py           # Full demo script
```

---

## ğŸ’¡ Key Features

âœ… **Fully Automated** â€“ No manual parameter tuning  
âœ… **Multi-Agent** â€“ 4 specialized LLM agents collaborate  
âœ… **Data-Driven** â€“ Decisions based on metrics + LLM reasoning  
âœ… **Hybrid Search** â€“ Combines vector (FAISS) + lexical (BM25)  
âœ… **LLM-as-Judge** â€“ Evaluates answer quality objectively  
âœ… **Production-Ready** â€“ Outputs clean YAML configuration  
âœ… **Cost-Efficient** â€“ ~$0.02-0.05 per optimization run  
âœ… **Extensible** â€“ Easy to add custom agents or metrics

---

## ğŸ§ª Example Use Cases

| Domain               | Documents                  | Optimization Focus                 |
| -------------------- | -------------------------- | ---------------------------------- |
| **Legal**            | Laws, court decisions      | Precise chunking for citations     |
| **Medical**          | Research papers, protocols | Context preservation across chunks |
| **Customer Support** | FAQs, tickets              | Fast retrieval, diverse sources    |
| **Technical Docs**   | API docs, guides           | Code snippet integrity             |
| **Finance**          | Reports, regulations       | Numerical data accuracy            |

---

## ğŸ“ˆ How It Works (Agent Reasoning Example)

**Chunk Architect Agent Prompt**:

```
You are analyzing a RAG retrieval report.

Current config:
- chunk_size: 1000 words
- overlap: 200 words

Observations from profiling:
- Average retrieval score: 0.52 (low)
- Many chunks contain multiple unrelated topics
- Top-3 chunks often miss key context

Task: Propose optimal chunk_size and overlap.
Reason step-by-step, then output JSON.
```

**Agent's Response**:

```json
{
  "reasoning": "Chunks are too large, mixing topics. Legal documents need precise retrieval. Smaller chunks (600 words) with moderate overlap (150) will improve precision while maintaining context.",
  "proposed_chunk_size": 600,
  "proposed_overlap": 150,
  "expected_impact": "+25-35% retrieval score, better source diversity"
}
```

---

## ğŸ”¬ Evaluation Methodology

1. **Baseline**: Run queries with default config
2. **Optimized**: Run same queries with agent-proposed config
3. **LLM Judge**: GPT-4o scores each answer (1-10) on:
   - Relevance
   - Completeness
   - Accuracy
   - Conciseness
4. **Compare**: Win/Loss/Tie statistics + avg score delta

---

## ğŸŒŸ Why This Matters

**Traditional RAG Development**:

- â° Hours of manual experimentation
- ğŸ² Trial and error, guesswork
- ğŸ“‰ Suboptimal configurations
- ğŸ’¸ Wasted API costs on poor retrievals

**With Auto-RAG Optimizer**:

- âš¡ 5-10 minutes automated
- ğŸ¤– AI reasoning + data analysis
- ğŸ“ˆ Measurable improvements
- ğŸ’° Optimized for quality AND cost

---

## ğŸ“ License

MIT License - Free for personal and commercial use.

---

## ğŸ¤ Contributing

Contributions welcome! Ideas:

- Add more agents (e.g., RerankerAgent, PromptAgent)
- Support more vector DBs (Pinecone, Weaviate, Qdrant)
- Custom evaluation metrics
- Multi-language support
- Web UI (Gradio/Streamlit)

---

## ğŸ”— Links

- **GitHub**: [Bellilty/auto-rag-optimizer](https://github.com/Bellilty/auto-rag-optimizer)
- **LinkedIn**: [Simon Bellilty](#)
- **Blog Post**: Coming soon...

---

## ğŸ“ Learn More About RAG

- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [FAISS Documentation](https://github.com/facebookresearch/faiss/wiki)
- [BM25 Algorithm Explained](https://en.wikipedia.org/wiki/Okapi_BM25)

---

<div align="center">

**Built with â¤ï¸ for the RAG community**

_If you find this useful, star the repo â­ and share on LinkedIn!_

[![Star on GitHub](https://img.shields.io/github/stars/Bellilty/auto-rag-optimizer?style=social)](https://github.com/Bellilty/auto-rag-optimizer)

</div>
