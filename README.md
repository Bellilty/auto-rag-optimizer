# ğŸ¤– AutoRAG Optimizer

**Multi-Agent RAG Evaluation and Architecture Refinement**

An automated pipeline for profiling, evaluating, and optimizing Retrieval-Augmented Generation (RAG) systems using cooperating AI agents.

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [How It Works](#-how-it-works)
- [Configuration](#-configuration)
- [Outputs](#-outputs)
- [Demo (Coming Soon)](#-demo-coming-soon)
- [Development](#-development)
- [License](#-license)

---

## ğŸ¯ Overview

AutoRAG Optimizer is a sophisticated multi-agent system that automatically analyzes and optimizes RAG pipelines. Instead of manually tweaking parameters, this system uses specialized AI agents to:

1. **Profile** your retrieval behavior
2. **Analyze** performance bottlenecks
3. **Propose** optimized configurations
4. **Evaluate** improvements quantitatively
5. **Output** a production-ready optimized configuration

### Why AutoRAG Optimizer?

Building an effective RAG system requires careful tuning of multiple parameters:

- Chunk size and overlap
- Retrieval methods (vector vs BM25 vs hybrid)
- Hybrid search weights
- Top-k parameters

This project automates the optimization process using LLM-powered agents that analyze your specific data and use cases.

---

## âœ¨ Features

### Multi-Agent Architecture

- **RetrieverProfilerAgent**: Profiles retrieval behavior, collects metrics (scores, diversity, BM25 vs vector analysis)
- **ChunkArchitectAgent**: Uses LLM reasoning to propose optimal chunking parameters based on profiling
- **EvaluatorAgent**: Runs comparative evaluations with LLM-based judging
- **ArchitectAgent**: Synthesizes all data into a final optimized configuration

### Hybrid Retrieval

- Vector search (semantic) using FAISS
- BM25 search (lexical) using rank-bm25
- Configurable hybrid weighting

### Comprehensive Evaluation

- LLM-based answer quality judging
- Baseline vs optimized comparisons
- Win rate calculations
- Per-query detailed metrics

### Clean Architecture

- Modular components (chunking, retrieval, evaluation)
- Reusable tools and utilities
- Clear separation of concerns
- Type hints and docstrings throughout

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RAG Optimization Workflow                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Baseline Index   â”‚
                    â”‚ (chunking +      â”‚
                    â”‚  vector + BM25)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ RetrieverProfilerAgent       â”‚
                â”‚ - Run test queries           â”‚
                â”‚ - Collect metrics            â”‚
                â”‚ - Detect issues              â”‚
                â”‚ â†’ retrieval_report.json      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ ChunkArchitectAgent          â”‚
                â”‚ - Analyze profiling          â”‚
                â”‚ - LLM proposes chunking      â”‚
                â”‚ â†’ chunk_proposal.json        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Rebuild Index    â”‚
                    â”‚ (new chunking)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ EvaluatorAgent               â”‚
                â”‚ - Evaluate baseline          â”‚
                â”‚ - Evaluate optimized         â”‚
                â”‚ - Compare results            â”‚
                â”‚ â†’ evaluation_report.json     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ ArchitectAgent               â”‚
                â”‚ - Synthesize reports         â”‚
                â”‚ - Generate final config      â”‚
                â”‚ â†’ optimized_config.yaml      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Responsibilities

| Agent                      | Input               | Output                   | Purpose                                       |
| -------------------------- | ------------------- | ------------------------ | --------------------------------------------- |
| **RetrieverProfilerAgent** | Test queries        | `retrieval_report.json`  | Profiles retrieval behavior and metrics       |
| **ChunkArchitectAgent**    | Profiling report    | `chunk_proposal.json`    | Proposes optimized chunking parameters        |
| **EvaluatorAgent**         | Both configurations | `evaluation_report.json` | Compares baseline vs optimized quantitatively |
| **ArchitectAgent**         | All reports         | `optimized_config.yaml`  | Synthesizes final production configuration    |

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10 or higher
- OpenAI API key ([get one here](https://platform.openai.com/api-keys))

### Setup

1. **Clone the repository**

```bash
git clone https://github.com/Bellilty/auto-rag-optimizer.git
cd auto-rag-optimizer
```

2. **Create a virtual environment**

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Set up environment variables**

Create a `.env` file in the project root:

```bash
OPENAI_API_KEY=your-api-key-here
```

Or export directly:

```bash
export OPENAI_API_KEY='your-api-key-here'
```

5. **Add documents**

Place your PDF or TXT documents in `data/raw_docs/`:

```bash
# Example: copy from existing rag-juridique project
cp ../rag-juridique/data/pdfs/* data/raw_docs/

# Or add your own documents
cp /path/to/your/documents/*.pdf data/raw_docs/
```

---

## ğŸš€ Quick Start

### Run Complete Optimization

```bash
python examples/sample_run.py
```

This will:

1. Build baseline index from your documents
2. Profile retrieval performance
3. Propose optimized chunking
4. Rebuild index with new chunking
5. Evaluate both configurations
6. Generate final optimized configuration

### Expected Output

```
================================================================================
                          AUTO-RAG OPTIMIZER
                Multi-Agent RAG Optimization Pipeline
================================================================================

STEP 1/6: Build Baseline Index
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”¨ Building baseline index...
...

STEP 2/6: Profile Baseline Retrieval
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ” Profiling retrieval on 10 queries...
...

STEP 3/6: Propose Optimized Chunking
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ—ï¸  Analyzing retrieval profile...
âœ… Proposed chunk size: 800 words (overlap: 180)
...

STEP 4/6: Build Optimized Index
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”¨ Building optimized index...
...

STEP 5/6: Evaluate Baseline vs Optimized
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Š Evaluating BASELINE configuration...
ğŸ“Š Evaluating OPTIMIZED configuration...
...

STEP 6/6: Generate Final Optimized Configuration
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ¯ Synthesizing final configuration...
...

================================================================================
                        OPTIMIZATION COMPLETE!
================================================================================
```

### Using Individual Agents

You can also run agents individually for more control:

```python
from src.components.index_builder import IndexBuilder
from src.components.retriever import HybridRetriever
from src.agents.retriever_profiler_agent import RetrieverProfilerAgent

# Build index
builder = IndexBuilder()
faiss_index, bm25_index, chunks = builder.load_indexes()

# Create retriever
retriever = HybridRetriever(faiss_index, bm25_index, chunks)

# Run profiler
profiler = RetrieverProfilerAgent(retriever)
report = profiler.run(
    queries_path="src/configs/test_queries.json",
    output_path="outputs/reports/retrieval_report.json"
)
```

---

## ğŸ“‚ Project Structure

```
auto-rag-optimizer/
â”‚
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                # Environment variables template
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestrator/           # Workflow coordination
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ workflow.py         # Main orchestration logic
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                 # LLM-driven decision agents
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ retriever_profiler_agent.py
â”‚   â”‚   â”œâ”€â”€ chunk_architect_agent.py
â”‚   â”‚   â”œâ”€â”€ evaluator_agent.py
â”‚   â”‚   â””â”€â”€ architect_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ components/             # Core RAG components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chunker.py          # Document chunking
â”‚   â”‚   â”œâ”€â”€ index_builder.py    # Embeddings + FAISS + BM25
â”‚   â”‚   â”œâ”€â”€ retriever.py        # Hybrid retrieval
â”‚   â”‚   â””â”€â”€ evaluator.py        # RAG evaluation
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                  # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_tools.py        # LLM interactions
â”‚   â”‚   â”œâ”€â”€ retriever_tools.py  # Retrieval analysis
â”‚   â”‚   â”œâ”€â”€ chunking_tools.py   # Chunking analysis
â”‚   â”‚   â””â”€â”€ evaluation_tools.py # Evaluation metrics
â”‚   â”‚
â”‚   â””â”€â”€ configs/                # Configuration files
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base_config.yaml    # Baseline configuration
â”‚       â””â”€â”€ test_queries.json   # Test queries
â”‚
â”œâ”€â”€ data/                       # Data directories
â”‚   â”œâ”€â”€ raw_docs/              # Place your PDF/TXT documents here
â”‚   â”œâ”€â”€ processed_docs/        # Processed documents (future use)
â”‚   â””â”€â”€ index/                 # FAISS and BM25 indexes
â”‚
â”œâ”€â”€ outputs/                   # Generated outputs
â”‚   â”œâ”€â”€ reports/              # Agent reports (JSON)
â”‚   â”œâ”€â”€ metrics/              # Evaluation metrics (JSON)
â”‚   â””â”€â”€ optimized_config.yaml # Final optimized configuration
â”‚
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ sample_run.py         # Example usage script
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ exploration.ipynb     # Jupyter notebook for exploration
```

---

## ğŸ”§ How It Works

### 1. Baseline Index Creation

The system first chunks your documents using baseline parameters (from `base_config.yaml`) and builds:

- **FAISS index**: For semantic (vector) search
- **BM25 index**: For lexical (keyword) search

### 2. Retrieval Profiling

The **RetrieverProfilerAgent** runs test queries and collects:

- Retrieval scores
- Score distributions
- Source diversity
- Vector vs BM25 contribution
- Potential issues (low scores, low diversity, etc.)

### 3. Chunking Optimization

The **ChunkArchitectAgent**:

- Analyzes the profiling report
- Uses an LLM to reason about optimal chunking
- Proposes new `chunk_size` and `overlap` parameters
- Validates the proposal

### 4. Index Rebuilding

The system re-chunks documents with the proposed parameters and rebuilds both indexes.

### 5. Evaluation

The **EvaluatorAgent**:

- Runs the same test queries on both configurations
- Uses an LLM judge to score answer quality (0-10)
- Compares baseline vs optimized
- Calculates win rate and improvement metrics

### 6. Final Configuration

The **ArchitectAgent**:

- Synthesizes all reports
- Uses LLM reasoning to finalize configuration
- Considers chunking, retrieval weights, top-k, etc.
- Outputs `optimized_config.yaml`

---

## âš™ï¸ Configuration

### Base Configuration (`src/configs/base_config.yaml`)

```yaml
chunking:
  chunk_size: 1000 # Words per chunk
  overlap: 200 # Overlapping words
  strategy: "word_based"

retrieval:
  method: "hybrid" # vector | bm25 | hybrid
  top_k: 5
  vector_weight: 0.7 # Hybrid weight for semantic search
  bm25_weight: 0.3 # Hybrid weight for lexical search

generation:
  model: "gpt-4o-mini"
  max_tokens: 500
  temperature: 0.3
```

### Test Queries (`src/configs/test_queries.json`)

```json
{
  "queries": [
    {
      "query": "What are the main principles?",
      "category": "general",
      "difficulty": "medium"
    },
    ...
  ]
}
```

Add your own domain-specific queries for better optimization results.

---

## ğŸ“Š Outputs

### Reports (`outputs/reports/`)

- **`retrieval_report.json`**: Profiling metrics
- **`chunk_proposal.json`**: Proposed chunking parameters
- **`evaluation_report.json`**: Baseline vs optimized comparison

### Metrics (`outputs/metrics/`)

- **`baseline_evaluation.json`**: Detailed baseline evaluation
- **`optimized_evaluation.json`**: Detailed optimized evaluation

### Final Configuration

- **`outputs/optimized_config.yaml`**: Production-ready configuration
- **`outputs/optimized_config.json`**: Same in JSON format

### Example Output Structure

```json
{
  "timestamp": "2024-01-15T10:30:00",
  "configuration": {
    "chunking": {
      "chunk_size": 800,
      "overlap": 180
    },
    "retrieval": {
      "method": "hybrid",
      "top_k": 5,
      "vector_weight": 0.65,
      "bm25_weight": 0.35
    }
  },
  "reasoning": "Reduced chunk size improves precision...",
  "expected_benefits": ["Better retrieval precision", "Improved diversity"],
  "confidence": "high"
}
```

---

## ğŸ¬ Demo (Coming Soon)

Future additions:

- **CLI interface** for interactive configuration
- **Web dashboard** for visualization
- **Jupyter notebooks** with step-by-step walkthroughs
- **API endpoints** for programmatic access

---

## ğŸ› ï¸ Development

### Running Tests

```bash
# Test individual components
python src/components/chunker.py
python src/tools/llm_tools.py

# Test agents
python src/agents/retriever_profiler_agent.py
```

### Adding Custom Agents

Create a new agent in `src/agents/`:

```python
class MyCustomAgent:
    def __init__(self, ...):
        pass

    def run(self, ...):
        # Your agent logic
        pass
```

Register it in the workflow orchestrator.

### Customizing Evaluation

Modify `test_queries.json` with domain-specific queries for your use case.

---

## ğŸ’° Costs

This project uses OpenAI APIs. Approximate costs for a typical run (10 queries, 3 documents):

| Operation                         | Tokens | Cost       |
| --------------------------------- | ------ | ---------- |
| Embeddings (baseline + optimized) | ~100K  | $0.002     |
| Profiling queries                 | ~10K   | $0.002     |
| LLM reasoning (agents)            | ~20K   | $0.005     |
| Evaluation (baseline + optimized) | ~50K   | $0.01      |
| **Total**                         | ~180K  | **~$0.02** |

For larger document sets, costs scale with:

- Number of chunks â†’ embedding costs
- Number of test queries â†’ evaluation costs

---

## ğŸ“š References

This project adapts and extends concepts from:

- [rag-juridique](https://github.com/Bellilty/rag-juridique) - Base RAG implementation
- LangChain - RAG patterns and best practices
- FAISS - Vector similarity search
- Rank-BM25 - Lexical search

---

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

- Additional chunking strategies (sentence-based, semantic, etc.)
- More sophisticated evaluation metrics
- Support for other LLM providers (Anthropic, local models)
- Web UI for visualization
- Additional optimization targets (latency, cost, etc.)

---

## ğŸ“ License

This project is open source and available for educational and commercial use.

---

## ğŸ‰ Acknowledgments

Built as a practical exploration of multi-agent systems for RAG optimization.

**Questions?** Open an issue or reach out!

---

**Happy Optimizing! ğŸš€**
